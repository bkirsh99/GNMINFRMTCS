---
title: "Genome Informatics A6"
author: ""
date: "24/02/2021"
#output: html_document
output:
  github_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#install any of these you might not have already
library(ggplot2)
library(edgeR)
library(reshape)
```
*Today we will be looking at a differential ATAC-seq dataset between cells treated with an anti BAF protac and control (untreated) cells. The cell type is HAP1, a cancer cell line with a near-haploid genome. We will use this dataset to explore differential analysis. *

*The GEO entry is located here, where you can read more about the experiments: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE148175 *

*This is the paper: https://www.nature.com/articles/s41588-021-00777-3 *

*"Acute BAF perturbation causes immediate changes in chromatin accessibility"*


```{r}
#download the data
atacSeqData = read.table(textConnection(readLines(gzcon(url("ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE148nnn/GSE148175/suppl/GSE148175_count_matrix_raw_atac_BRM014_ACBI1.csv.gz")))), 
                      sep=",", stringsAsFactors = FALSE, header = TRUE)

#glimpse(atacSeqData) ##data.frame with 56,617 rows (coverage) and 25 columns (1 region; 24 samples)
```


```{r}
#create a sample metadata data.frame
samples = data.frame(ID = names(atacSeqData)[2:ncol(atacSeqData)])
samples$replicate = gsub("(R[12])_([0-9]+[minh]+)_(.*)$","\\1",samples$ID)
samples$timeName = gsub("(R[12])_([0-9]+[minh]+)_(.*)$","\\2",samples$ID)
samples$treatment = gsub("(R[12])_([0-9]+[minh]+)_(.*)$","\\3",samples$ID)
samples$treatment[samples$treatment=="N"]="BRM014"
samples$time= as.numeric(gsub("[a-z]*","",samples$timeName))
samples$time[grepl("min",samples$timeName)]=samples$time[grepl("min",samples$timeName)]/60

#glimpse(samples) ##data.frame with 24 rows (samples) and 5 columns (ID, replicate, timeName, treatment, time)
```


# Part 1: understanding the experiment

*Now using `samples` make a plot showing the experimental design, with time on the x axis, treatment on the y axis, and one plot on the left and one on the right for the two replicates (e.g. using `facet_grid`).*

### `#?#` *Make the above plot. Each point should represent one of the samples.  - 1 pt*
```{r}
#here, if the point is there, it means such a sample exists, if absent it means that there is no such sample

p <- ggplot(samples, aes(x=time, y=treatment)) + geom_point()
p + facet_grid(cols = vars(replicate))

```

*In this study, one of the things they were comparing was BRM014 to DMSO. The drug BRM014 is dissolved in DMSO, so DMSO alone is the appropriate control to gauge the effect of BRM014.*

### `#?#` *Can we compare BRM014 to DMSO across all time points? Why/why not?  - 1 pt*

#ANSWER: No. We can only compare BRM014 to DMSO at the time points 5min and 24h, since there is no such DMSO sample at the remaining time points (i.e., 10min, 30min, 1h, and 6h). Thus, the appropriate control to gauge the effect of BRM014 is only present at the first and last time points. 

```{r}
#NOTE: We can further inspect the data.frame to verify this answer.

samples[samples$treatment=="DMSO",]
samples[samples$treatment=="BRM014",]

```


# Part 2: QC

*With most genomics data, it is important both that samples have sufficient coverage, and that the samples have similar coverage. Either case can lead to underpowered analysis, or misleading results. Calcualte the read coverage for each sample. *

### `#?#` Make a plot with read coverage on the y-axis (total number of reads) and the samples on the x-axis. - 3 pt*

```{r}
# there are many ways you could do this; one of which is using the melt/cast functions from reshape

count_matrix <- atacSeqData[,2:ncol(atacSeqData)] #build a count matrix from the original data set by removing the "region" column
sum_matrix <- data.frame(t(colSums(count_matrix))) #sum the columns to calculate the total number of reads for every sample
melt_matrix <- melt(sum_matrix, id.vars=c()) #melt the matrix to facilitate plotting

q <- ggplot(data=melt_matrix, aes(x=variable, y=value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
q

```

### `#?#` *Which sample has the most coverage? - 0.5 pt*
```{r}

melt_matrix[which.max(melt_matrix$value),]

#ANSWER: The sample with the highest coverage is R1_24h_DMSO, totaling 4,686,253 reads.

```

### `#?#` *Which sample has the least? - 0.5 pt*
```{r}

melt_matrix[which.min(melt_matrix$value),]

#ANSWER: The sample with the lowest coverage is R1_6h_control, totaling 2,341,332 reads.

```

### `#?#` *What is the % difference between the max and min (relative to the min)? - 0.5 pt*
```{r}

max <- melt_matrix[which.max(melt_matrix$value),2]
min <- melt_matrix[which.min(melt_matrix$value),2]
pct <- ( max - min ) / min * 100
pct

#ANSWER: The percent difference is 1.001533, meaning that R1_24h_DMSO has 100.1533% greater coverage than R1_6h_control.

```

*In cases where samples have vastly different coverage, you can potentially down-sample the higher-coverage samples. Sometimes, throwing out the data in this way can also introduce new problems, so we're going to stick with the data we have.*

*For this assignment, we will look only at BI_protac vs control data. *

### `#?#` *Create a new data.frame containing only the BI_protac and control samples - 1 pt*
```{r}

library(dplyr)
filters <- c('BI_protac' , 'control')
atacSeqData_BI_protac_control <- atacSeqData[, c('region',grep(paste(filters, collapse = "|"),names(atacSeqData),value=TRUE))] #new data.frame containing only BI_protac and control samples

```

### `#?#` *For this subset, calculate the counts per million reads (CPM) for each sample - 2 pt*
```{r}

count_matrix2 <- atacSeqData_BI_protac_control[,2:ncol(atacSeqData_BI_protac_control)] #build a new count matrix for this subset
cpm_BI_protac_control <- data.frame(cpm(count_matrix2))

```


### `#?#` *Plot the kernel density estimate for CPM (x axis). 1 curve per sample, different colours per curve. - 1 pt*

```{r}

library(reshape2)
melt_cpm_BI_protac_control <- melt(cpm_BI_protac_control, id.vars=c())
r <- ggplot(melt_cpm_BI_protac_control, aes(x=value, color=variable)) + geom_density() + labs(title= "Kernel density estimate for counts per million reads (CPM)", y = "Density", x = "Counts per million (CPM)", color = "Sample")
r

```

### `#?#` *Plot the kernel density estimate for log(CPM+1) (x axis), coloured as before - 1 pt*

```{r}

melt_log_cpm_BI_protac_control <- mutate(melt_cpm_BI_protac_control, value = log(value+1))
s <- ggplot(melt_log_cpm_BI_protac_control, aes(x=value, color=variable)) + geom_density() + labs(title= "Kernel density estimate for normalized counts per million reads (log(CPM+1))", y = "Density", x = "Normalized counts per million (log(CPM+1))", color = "Sample")
s

```

### `#?#` *Why do you think log-transforming is usually performed when looking at genomics data? What about adding 1 before log transforming? - 2 pt*

#ANSWER: In genomics data, distributions are usually highly skewed and heteroscedasticity results in biased statistical tests. Thus, log transformation can be used to approximate a normal distribution, which is required to meet the assumptions of certain tests, improve symmetry, and better accomodate orders of magnitude of differential expression. Furthermore, the log scale informs on relative changes, while the linear scale informs on absolute changes. In genetic analysis, particularly differential expression analysis, relative changes are often more interesting than absolute differences. Because the logarithm of zero, log(0), is udefined, adding a constant value to every data point prior to applying the log transform is a good practice. This is especially important in studies where the control group dose is set to zero and log(x) does not exist.


### `#?#` *Some regions have very large CPMs. Inspect the peaks for which CPM>400. What do you notice about them? 3 pt*
```{r}

cpm_BI_protac_control$region <- atacSeqData_BI_protac_control$region
melt_cpm_BI_protac_control_region <- melt(cpm_BI_protac_control, id.vars = "region")
cpm_400_BI_protac_control <- filter(melt_cpm_BI_protac_control_region, value > 400)
table(cpm_400_BI_protac_control$region)

#ANSWER: The peaks are located either on chr1 (11) or chrM (40), but mainly on the mitochondrial chromosome. The contamination from chrM contributes to large fraction of the unusable reads in ATAC-seq analysis, since  the mitochondrial genome is nucleosome-free and thus widely accessible to Tn5 insertion.

```

*Normally, we would remove some of these regions before continuing (and would redo the above steps). Since this is an assignment, we will continue with the data as-is.*

*Often a good first step is to see if the data look good. One way to do this is by seeing whether or not the signals in each sample correlate with each other in ways you expect.*

### `#?#` *Calculate the pairwise correlations between log(CPM+1)s for the samples and plot them as a heatmap (samples x samples) - 3 pt*
```{r}

#norm_cpm_df <- log( cpm_df[, -which(names(cpm_df) == "region")] + 1 )
norm_cpm_BI_protac_control <- log( data.frame(cpm(count_matrix2)) + 1 )
cc <- cor(norm_cpm_BI_protac_control, method = "pearson")
melt_cc <- melt(cc)
t <- ggplot(data = melt_cc, aes(x=Var1, y=Var2, fill=value)) + geom_tile(color = "white",aes(fill = value)) +  geom_text(aes(label = round(value, 2))) +  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
t

```

### `#?#` *What do you expect the correlations between replicates to look like? Is that what you see? - 2 pt*

#ANSWER: I would expect the correlation coefficient to be close to 1.0, at a strong but not exaclty perfect value. This would indicate a "good" replication with highly positive statistical relationship between replicates, which is in fact observed in the heatmap. The correlation between replicates ranges from 0.86 to 0.89.   

``` {r}

#NOTE: We can further inspect the r values for the correlation between replicates.

filter(melt_cc, substring(melt_cc$Var1,3)==substring(melt_cc$Var2,3) & melt_cc$Var1 != melt_cc$Var2)

```

*It is common to exclude some regions from analysis. For instance, we won't be able to robustly identify those that are differential but have low coverage even if they are truly differential, so there is no point testing these. We will also remove mitochondrial regions, a common contaminant of ATAC-seq data.*


### `#?#` *Filter your data, retaining only regions where the average counts per sample is greater than 10, and also remove mitochondrial regions - 3 pt*
```{r}

filtered_atacSeqData <- atacSeqData_BI_protac_control[rowSums(atacSeqData_BI_protac_control < 10)==0, , drop = FALSE]
filtered_atacSeqData <- filtered_atacSeqData[!grepl("chrM",filtered_atacSeqData$region),]
#this data.frame contains only BI_protac and control samples and non-mitochondrial regions with average counts greater than 10

```

### `#?#` *How many peaks did you have before? How many do you have now? - 1 pt*
```{r}

peaks_before <- nrow(atacSeqData_BI_protac_control)
peaks_after <- nrow(filtered_atacSeqData)

peaks_before
peaks_after

#ANSWER: Before, there were 56,617 peaks. Now, there are 42,351.

```


# Part 3: Differential ATAC

*We want to know what regions are differentially accessible between BI_protac and the control.* 

*Today, we're going to use edgeR, which is designed for RNA-seq, but works well on ATAC-seq as well. The user guide is here:* https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf


### `#?#` *Make a count matrix called `countMatrix` for the BI_protac and control samples, including only the peaks we retained above - 2 pt*
```{r}

countMatrix <- filtered_atacSeqData[,2:ncol(filtered_atacSeqData)]

```

*EdgeR is exceptionally versatile, with many different options for analysis. Today, you're going to use the GLM-quasi-likelihood approach to calculate differential accessibility. We are providing the first example analysis below, which you can modify in subsequent steps. You will need to understand what the steps do, so read the appropriate documentation. *
```{r}
curSamples = samples[match(names(countMatrix), samples$ID),];
y = DGEList(counts=countMatrix, group=curSamples$treatment)
y = calcNormFactors(y)
designPaired = model.matrix(~curSamples$treatment + curSamples$timeName)  
# we are using timeName here to make sure that time is treated as a categorical variable. Had we more time points it might make sense to treat time as a value.
y = estimateDisp(y, designPaired)
fitPaired = glmQLFit(y, designPaired)
qlfPairedTime6vs24 = glmQLFTest(fitPaired, coef=3) 
qlfPairedTreatControlvsProtac = glmQLFTest(fitPaired, coef=2)

allDEStatsPairedTreatControlvsProtac = as.data.frame(topTags(qlfPairedTreatControlvsProtac,n=nrow(countMatrix)))
allDEStatsPairedTreatControlvsProtac$region=row.names(allDEStatsPairedTreatControlvsProtac)

allDEStatsPairedTime6vs24 = as.data.frame(topTags(qlfPairedTime6vs24,n=nrow(countMatrix)))
allDEStatsPairedTime6vs24$region=row.names(allDEStatsPairedTime6vs24)

```
*While the differential analysis has been done in this case, before we look at the results, we are going to check if the data appear to be normalized correctly. Also include a loess line of best fit, and the line y=0.*

### `#?#` *Make an MA plot for allDEStatsPairedTreatControlvsProtac -2pt*
```{r}

de <- decideTestsDGE(qlfPairedTreatControlvsProtac, p=0.05, adjust='BH')
detags <- rownames(qlfPairedTreatControlvsProtac)[as.logical(de)]
plotSmear(qlfPairedTreatControlvsProtac, de.tags=detags, main='MA Plot for allDEStatsPairedTreatControlvsProtac', lowess=TRUE)
abline(h = 0, col = 'blue')

```

### `#?#` *Make an MA plot for allDEStatsPairedTime6vs24 - 1 pt*
```{r}

de2 <- decideTestsDGE(qlfPairedTime6vs24, p=0.05, adjust='BH')
detags2 <- rownames(qlfPairedTime6vs24)[as.logical(de)]
plotSmear(qlfPairedTime6vs24, de.tags=detags, main='MA Plot for allDEStatsPairedTime6vs24', lowess=TRUE)
abline(h = 0, col = 'blue')

```

*Now we're going to test loess normalization instead.* 


### `#?#` *Perform the same differential peak analysis using loess regularization. - 1 pt*
```{r}
#Note: the Bioconductor package csaw implements loess regularization in a way that is compatible with edgeR
library(csaw)

y_loess <- DGEList(counts=countMatrix, group=curSamples$treatment)
y_loess <- normOffsets(y_loess)
y_loess <- estimateDisp(y_loess, designPaired)
fitPaired_loess <- glmQLFit(y_loess, designPaired)
qlfPairedTime6vs24_loess <- glmQLFTest(fitPaired_loess, coef=3) 
qlfPairedTreatControlvsProtac_loess <- glmQLFTest(fitPaired_loess, coef=2)

```

### `#?#` *Make the same two MA plots as before, but this time using the loess normalized analysis - 1 pt*
```{r}

de3 <- decideTestsDGE(qlfPairedTreatControlvsProtac_loess, p=0.05, adjust='BH')
detags3 <- rownames(qlfPairedTreatControlvsProtac_loess)[as.logical(de)]
plotSmear(qlfPairedTreatControlvsProtac_loess, de.tags=detags, main='MA Plot for loess-normalized allDEStatsPairedTreatControlvsProtac', lowess=TRUE)
abline(h = 0, col = 'blue')

de4 <- decideTestsDGE(qlfPairedTime6vs24_loess, p=0.05, adjust='BH')
detags4 <- rownames(qlfPairedTime6vs24_loess)[as.logical(de)]
plotSmear(qlfPairedTime6vs24_loess, de.tags=detags, main='MA Plot for loess-normalized allDEStatsPairedTime6vs24', lowess=TRUE)
abline(h = 0, col = 'blue')
#plotMD(qlfPairedTreatControlvsProtac_loess,)


```

### `#?#` *What was the first normalization method? What changed in the MA plots? Which analysis do you think is more reliable and why? - 4 pt*

#ANSWER: The first normalization method was TMM, which utilizes scaling factors based on the weighted trimmed mean of M-values to convert raw library sizes into effective library sizes. The differences between TMM and loess normlization are most noticeable in the shape of the loess lines, especially between the "TreatControlvsProtac" plots. Since this line visually indicates the amount of bias in differential accessibility with a fixed threshold (M=1 or M=-1), a more reliable analysis is achieved when it is horizontal at M=0. Furthermore, the TMM normalization method assumes that most regions of the genome are not truly differentially accessible, and should be applied when signal differences are most likely to be caused by technical artifacts or systematic biases in library ATAC distribution (e.g., mapping errors, PCR duplicates). 

# Part 4: GC bias

*Next, we will look at potential GC bias in the data. We will again use bioconductor *

### `#?#` *Convert the region IDs to a GRanges object - 3 pt*
```{r}
#note that the names of your peaks are of the format <chr>:<startPos>-<endPos>
library(GenomicRanges)

atac_GRanges <- GRanges(filtered_atacSeqData$region)

```


### `#?#` *Extract the genomic DNA sequences for each peak using hg38 - 3 pt*
*See for relevant documentation: https://bioconductor.org/packages/release/workflows/vignettes/sequencing/inst/doc/sequencing.html *
```{r}
library(Biostrings)
library(BSgenome.Hsapiens.UCSC.hg38)

dna_sequences <- getSeq(Hsapiens, atac_GRanges)
filtered_atacSeqData$GC <- letterFrequency(dna_sequences, "GC", as.prob=TRUE)

```


*Now we will see if there's any relationship between peak CPM and GC content for each of the samples.*

### `#?#` *Create scatter plots (one per sample, e.g. using facet_wrap), including lines of best fit (GAM), where each plot shows GC content (x axis) vs CPM (y axis) for each peak (points) -2pt*
```{r}
#please limit the y axis to between 0 and 50

library(reshape2)
library(ggplot2)
require(mgcv)

cpm_filtered_atacSeqData <- data.frame(cpm(countMatrix))
cpm_filtered_atacSeqData$region <- filtered_atacSeqData$region
cpm_filtered_atacSeqData$GC <- filtered_atacSeqData$GC
melt_cpm_atacSeqData <- melt(cpm_filtered_atacSeqData, id.vars=c("region","GC"))
u <- ggplot(melt_cpm_atacSeqData, aes(x=GC, y=value)) + geom_point() + ylim(0,50) + stat_smooth(method = "gam")
u + facet_wrap(~variable)

```

### `#?#` *Repeat the above, but this time showing only the lines of best fit and all on the same plot - 2 pt*
```{r}

library(ggplot2)
require(mgcv)

v <- ggplot(melt_cpm_atacSeqData, aes(x=GC, y=value, col = factor(variable))) + ylim(0,50) + stat_smooth(method = "gam")
v + labs(title= "GC Content vs. CPM for Peaks", y = "CPM", x = "GC Content", color = "Sample")

```


### `#?#` *Given this result, predict whether we will see a significant relationship between GC content and logFC in our differential peak analysis (loess-normalized). Justify your prediction. Predicting "wrong" will not be penalized, as long as your justification is correct. Don't retroactively change your answer. - 2 pt*

#ANSWER: In regions of low (<0.5) or high (>0.7) GC content, noticeable variations in CPM are observed for the peaks in each sample. However, regions of moderate (0.5-0.6) GC content have a consistent CPM across all samples. Thus, I believe that there will be a significant relationship between GC content and logFC in our loess-normalized Differential accessibility analysis, since the plot above demonstrates a sample-specific relationship between the number of reads and the abundance of GC nucleotides in any given peak.


### `#?#` *Plot the relationship between GC and logFC for the loess-normalized ControlvsProtac analysis. Also include a line of best fit (blue) and y=0 (red) - 2 pt*
```{r}


allDEStatsPairedTreatControlvsProtac_loess <- as.data.frame(topTags(qlfPairedTreatControlvsProtac_loess,n=nrow(countMatrix)))
filtered_atacSeqData$logFC <- allDEStatsPairedTreatControlvsProtac_loess$logFC[match(row.names(allDEStatsPairedTreatControlvsProtac_loess),row.names(filtered_atacSeqData))]
melt_loess_atacSeqData <- melt(filtered_atacSeqData, id.vars=c("region","GC","logFC"))
w <- ggplot(melt_loess_atacSeqData, aes(x=GC, y=logFC)) + stat_smooth(method = "gam") + geom_hline(yintercept=0, color = "red")
w + labs(title= "GC Content vs. logFC for Loess-Nornmalized Peaks", y = "logFC", x = "GC Content")


```

### `#?#` *Now plot the same thing for the NON loess-normalized ControlvsProtac analysis. - 1 pt*
```{r}

filtered_atacSeqData$logFC_null <- allDEStatsPairedTreatControlvsProtac$logFC[match(row.names(allDEStatsPairedTreatControlvsProtac),row.names(filtered_atacSeqData))]
melt_atacSeqData_null <- melt(filtered_atacSeqData, id.vars=c("region","GC","logFC_null"))
x <- ggplot(melt_atacSeqData_null, aes(x=GC, y=logFC_null)) + stat_smooth(method = "gam") + geom_hline(yintercept=0, color = "red")
x + labs(title= "GC Content vs. logFC for Non Loess-Nornmalized Peaks", y = "logFC", x = "GC Content")

```


### `#?#` *Was your prediction correct? Do you think we should also account for GC normalization in our differential ATAC analysis? Why/why not? - 3 pt*

#ANSWER: Yes, my prediction was correct and as mentioned before, regions with very low or very high GC content seem to be more greatly affected. I believe that we should apply GC normalization to account for GC-content effects in ATAC-seq analysis because differential accessibility can be affected by sample-specific technical artifacts such as enzymatic cleavage effects, PCR bias, and duplicate reads. These factors have a dowstream impact on the GC content of a sample and bias ATAC analyses, which are largely based on logFC metrics.

*We will leave GC normalization as an optional exercise, and will not actually do it here.*

# Part 5: Differential analysis results

### `#?#` *Suppose we perform the analyses above, redoing the differential analysis once more with GC normalization, and also considering that we tested loess and the default normalization methods. Did we P-hack? Why or why not? - 2 pt*

#ANSWER: Yes, we p-hacked because we conducted our analysis using data that was manipulated based on tests that demonstrated to yield significant results. Thus, it is impossible to assess the likelihood that chance alone would produce patterns in our data set because it had already been filtered to retain only significant entries prior to hypothesis testing.

*Going forward, we will only use the initial analysis (**not loess normalized**)*

### `#?#` *Now considering the two comparisons (6 vs 24 hours, and protac vs control). EdgeR performed a correction for MHT, but if we want to analyze the results from both comparisons, do we need to re-adjust to account for the fact that we tested two different hypothesis sets (time and treatment)? Why/not? - 2 pt*

#ANSWER: 
#because the glm approach allows an infinite variety of contrasts to be tested between the groups, so long as we form and test these contrasts appropriately. Thus, we must utilize nested interaction formulas to build a design matrix with enough contrasts to be able to compare (6 AND protac) vs. (24 AND protac) vs. (6 AND control) vs. (24 AND control). This way, we can consider all the levels of time for each treatment drug separately and analyze them to identify the peaks that are significantly differentially accessible for all four contrasts.


### `#?#` *How many differential peaks did you find (FDR<0.01). - 1 pt*
```{r}

y2 = DGEList(counts=countMatrix, group=curSamples$treatment)
y2 = calcNormFactors(y2)
design2 <- model.matrix(~curSamples$treatment + curSamples$treatment:curSamples$timeName)
y2 = estimateDisp(y2, design2)
fit <- glmQLFit(y2, design2)

qlfPairedAll <- glmQLFTest(fitPaired, contrast=c(0,-1,1))
allDEStatsPairedAll = as.data.frame(topTags(qlfPairedAll,n=nrow(countMatrix)))
allDEStatsPairedAll$region=row.names(allDEStatsPairedAll)

nrow(allDEStatsPairedAll[allDEStatsPairedAll$FDR<0.01, ])
nrow(allDEStatsPairedTime6vs24[allDEStatsPairedTime6vs24$FDR<0.01, ])

nrow(allDEStatsPairedTreatControlvsProtac[allDEStatsPairedTreatControlvsProtac$FDR<0.01, ])
pct2 <- nrow(allDEStatsPairedTreatControlvsProtac[allDEStatsPairedTreatControlvsProtac$FDR<0.01, ]) / nrow(allDEStatsPairedTreatControlvsProtac) * 100

#ANSWER: There are 324 differential peaks (FDR<0.01), which is equivalent to 0.765% of total peaks.

```

### `#?#` *Make a volcano plot of the allDEStatsPairedTreatControlvsProtac, with -log10(p-value) on the y axis and logFC on the x. Colour points that are significant at an FDR<0.01. - 2 pt*
```{r}

allDEStatsPairedTreatControlvsProtac$colors <- "Non-significant"
allDEStatsPairedTreatControlvsProtac[which(allDEStatsPairedTreatControlvsProtac$FDR < 0.01),"colors"] <- "Significant"
mycolors <- c("red", "black")
names(mycolors) <- c("Significant", "Non-significant")
z <- ggplot(allDEStatsPairedTreatControlvsProtac, aes(x=logFC, y=-log10(PValue), group=colors)) + geom_point(aes(color=as.factor(colors))) + scale_colour_manual(values = mycolors)
z + labs(title= "Volcano Plot of allDEStatsPairedTreatControlvsProtac", color = "Significance")

```



### `#?#` *Plot the logCPM (x axis) by -log10(Pvalue) (y axis), again colouring by FDR<0.01. - 2 pt*
```{r}

a <- ggplot(allDEStatsPairedTreatControlvsProtac, aes(x=logCPM, y=-log10(PValue), group=colors)) + geom_point(aes(color=as.factor(colors))) + scale_colour_manual(values = mycolors)
a + labs(title= "Plot of logCPM vs -log10(PValue) for allDEStatsPairedTreatControlvsProtac", color = "Significance")

```

### `#?#` *Do you think our initial filtering on peaks with at least 10 reads on average per sample was a good choice? Why or why not?*

#ANSWER: Yes, regions that have very low counts across all the libraries should be removed prior to downstream analysis. From a biological perspective, a region must be accessible at some minimal level to constitute biologically relevant open chromatin, such as transcription factor binding sites or DNA methylation sites. From a statistical point of view, regions with consistently low counts cannot be accurately or reliably identified as significantly differentially accessible due to the lack of statistical evidence. However, I would recommend filtering on a count-per-million (CPM) basis rather than absolute counts, as to avoid favoring regions that are accessible in larger libraries over those in smaller libraries.

*At this point there are many other follow ups you can and would do for a real differential analysis, but we leave these as optional exercises. For example:*
1. Confirming that the differential peaks look correct (e.g. CPM heatmap)
2. Confirming that peaks look differential on the genome browser
3. Looking for motif enrichment
4. Performing a GREAT analysis, including functional enrichment and assigning peaks to genes

*Knit your assignment as a github_document and submit the resulting .md and this .Rmd to your github, and complete the assignment submission on Canvas. Make sure to include the graphs with your submission. *
 

